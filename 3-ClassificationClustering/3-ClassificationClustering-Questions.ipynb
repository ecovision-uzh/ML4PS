{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY_NX952rthX"
   },
   "source": [
    "# Classification & Clustering\n",
    "\n",
    "**Team work is not allowed.** Everybody implements his/her own code. Discussing issues with others is fine, sharing code with others is not.\n",
    "\n",
    "## Part 1: Forest Cover Type Classification\n",
    "\n",
    "In this exercise, we will **predict the forest cover type** (the predominant kind of tree cover) from strictly cartographic variables. \n",
    "As in the regression assignment, Y stands for a column vector of \"target\" values, that is the i-th row of Y contains the desired output for the i-th data point. Contrary to regression, the elements of Y in this classification task are integer values.\n",
    "\n",
    "We will work with several popular classifiers provided by Scikit-learn package.\n",
    "\n",
    "## Dataset: Forest cover data\n",
    "This dataset contains 581012 tree observations from four areas of the Roosevelt National Forest in Colorado. All observations are cartographic variables (no remote sensing) from 30 meter x 30 meter sections of forest. \n",
    "\n",
    "This dataset includes information on tree type, shadow coverage, distance to nearby landmarks (roads etcetera), soil type, and local topography.\n",
    "\n",
    "### Data Dictionary\n",
    "\n",
    "|Variable Name | Description |\n",
    "|-|-|\n",
    "| Elevation | Elevation in meters.|\n",
    "| Aspect | Aspect in degrees azimuth.|\n",
    "| Slope | Slope in degrees.|\n",
    "| Horizontal_Distance_To_Hydrology | Horizontal distance to nearest surface water features.|\n",
    "| Vertical_Distance_To_Hydrology | Vertical distance to nearest surface water features.|\n",
    "| Horizontal_Distance_To_Roadways | Horizontal distance to nearest roadway.|\n",
    "| Hillshade_9am | Hill shade index at 9am, summer solstice. Value out of 255.|\n",
    "| Hillshade_Noon | Hill shade index at noon, summer solstice. Value out of 255.|\n",
    "| Hillshade_3pm | Hill shade index at 3pm, summer solstice. Value out of 255.|\n",
    "| Horizontal_Distance_To_Fire_Points | sHorizontal distance to nearest wildfire ignition points.|\n",
    "| Wilderness_Area1 | Rawah Wilderness Area|\n",
    "| Wilderness_Area2 | Neota Wilderness Area|\n",
    "| Wilderness_Area3 | Comanche Peak Wilderness Area|\n",
    "| Wilderness_Area4 | Cache la Poudre Wilderness Area|\n",
    "| Soil_Type| Soil_Type1 to Soil_Type40 (Total 40 Types)|\n",
    "| **Cover_Type** | Forest Cover Type designation. |\n",
    "\n",
    "**Cover_Type** Integer value between 1 and 7, with the following key:\n",
    "\n",
    "    1. Spruce/Fir\n",
    "    2. Lodgepole Pine\n",
    "    3. Ponderosa Pine\n",
    "    4. Cottonwood/Willow\n",
    "    5. Aspen\n",
    "    6. Douglas-fir\n",
    "    7. Krummholz\n",
    "\n",
    "\n",
    "\n",
    "## Objective: \n",
    "\n",
    "We will **predict different cover types** in different wilderness areas of the Roosevelt National Forest of Northern Colorado with the best accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8GLQQAjrthc"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-3KN3MIrthd"
   },
   "source": [
    "## 1) Load data\n",
    "\n",
    "- Use ```pandas.read_csv()``` to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHouNJh_rthe"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ForestCover.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gIQcuptrthe"
   },
   "source": [
    "- Visualize the first and the last 5 rows of the data, using ```.head()``` and ```.tail()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDvLkknYrthf",
    "outputId": "9e458c16-9aee-48cb-b72b-ba40e05f90ff"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaNGqBpMrthg",
    "outputId": "962dba48-9b7d-4889-c2f4-4ae9b7b2a149"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TP8sxlprthh"
   },
   "source": [
    "## 2) Basic statistics\n",
    "- Print overall info, using ```.info()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sG8wNwJPrthh",
    "outputId": "46e34862-9bc0-46a1-9e1f-c74283cb086b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9jPadYQrthh"
   },
   "source": [
    "- Print dataframe statistics using ```.describe()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cPYA7xrrthi",
    "outputId": "af966382-9348-4814-a3c2-763245a98ae8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mdMVvJXrthi"
   },
   "source": [
    "- Check if there are missing values, using ```.isnull().sum()```. If yes, drop them or fill them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsCHQmTfrthi",
    "outputId": "beb71a3f-bd9d-4f99-863e-345c08bad640"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kmrmqKYrthj"
   },
   "source": [
    "## 3) Exploratory Data Analysis\n",
    "- Show the category distribution, using ```.value_counts()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wf-2lCurthj",
    "outputId": "4edb4f88-edff-4915-f70f-0a288f8b6b8d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1PD4CJBrthj"
   },
   "source": [
    "- Visulise this distribution, using ```sns.countplot()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0jRHXuJrthj",
    "outputId": "6418abc2-2cfd-4320-fda0-78e13dfe8414"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fRmUWFcrthk"
   },
   "source": [
    "### Feature Histograms \n",
    "- Visulize data distribution of the first four features via Histograms using ```sns.histplot()```. (Show four figures.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfUn3Z55rthk",
    "outputId": "27e7d403-9de9-49ff-a452-50bd48c252eb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uv6s1bDvrthk"
   },
   "source": [
    "### Correlation between Variables\n",
    "- Show correlation between variables, using ```sns.heatmap()```. (Since 55 columns are too many, please show here a 10x10 heatmap for the first 10 features. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62suf7Twrthl",
    "outputId": "e07feb3f-525e-4112-fb61-2de05ce53a82"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8y2IhG4rthl"
   },
   "source": [
    "### Data Distribution w.r.t. Categories\n",
    "- Show data distribution w.r.t. categories, using ```sns.boxplot()```. (x-axis: cover type, y-axis: feature variable, please show 10 figures for the first 10 variables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DhdPMnCRrthl",
    "outputId": "50d1566f-9970-4b22-8077-ac8efa83c653"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXIChG9Zrthl"
   },
   "source": [
    "- Are there any features which shows not much of variance with respect to classes? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJZerGRNrthl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3HYn9NJrthm"
   },
   "source": [
    "- Which features might do good job in the prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrCLD3xerthm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lskHWLpwrthm"
   },
   "source": [
    "## 4) Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhUoR4_6rthm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHBdrZfFrthm"
   },
   "source": [
    "- Define Feature (as X) and Target (as y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZ1XYs09rthm"
   },
   "outputs": [],
   "source": [
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dfcmnzfrthm"
   },
   "source": [
    "- Split the data into train (70%) and test (30%), use a random seed.\n",
    "- Print the size of the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4l5onhRerthm"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBUzT6-srthn",
    "outputId": "7ff334e3-93fa-499b-91aa-a4b260552b9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHhRH0iyrthn"
   },
   "source": [
    "- Normalize the data using ```StandardScaler()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5g2zgRZmrthn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESJBwv0Drthn"
   },
   "source": [
    "### 4a) Logistic Regression\n",
    "- Train the Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XR03dCgQrthn",
    "outputId": "24be4b3d-560e-4968-a33b-2c1e9a1e13a0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_RKe_5Crthn"
   },
   "source": [
    "- Predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dcjpo8mFrthn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99CFumeQrtho"
   },
   "source": [
    "- Compute and print performance metrics, using ```accuracy_score()``` to compute the fraction of correctly classified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_hsIhTxrtho",
    "outputId": "dae081f2-72e2-4e4e-c6a6-f5aabba9c74f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJB4KVNqrtho"
   },
   "source": [
    "### 4b) Random Forest\n",
    "- Train and test with the Random Forest classifier\n",
    "- Print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1sCEFSTrtho",
    "outputId": "630dc332-e628-49d9-c9f7-4a341e588909"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jP3M_Ycsrtho",
    "outputId": "d3208ffa-d479-4262-abb2-e8f323314917"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBjMgogLrthp"
   },
   "source": [
    "### 4c) K Nearest Neighbor\n",
    "- Train and test with the KNN classifier\n",
    "- Print the accuracy\n",
    "\n",
    "(It might take a bit long, around an hour if using one cpu core.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8X-sBOgnrthp",
    "outputId": "bb88af42-a2b9-4d93-9beb-0746d3089374"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMS0f0MTrthp",
    "outputId": "d8c9231b-1845-4cdc-db4f-00c5a1b37f85"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a65R6st3rthq"
   },
   "source": [
    "### OPTIONAL 4d) Support Vector Machine\n",
    "- Train and test with the SVM classifier\n",
    "- Print the accuracy\n",
    "\n",
    "(It might take a bit long, around 3 hours if using one cpu core...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHzcwQNXrthq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIbgrA-5rthq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3REQPMxWrthq"
   },
   "source": [
    "### Conclusion\n",
    "- Please write your conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) sklearn K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, MeanShift\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Toy dataset: blobs\n",
    "- Load toy dataset (blobs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_blobs = np.genfromtxt('toy_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use sklearn kmeans function (parameters by defalt) to cluster points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot clustering results using ```plt.scatter()``` and color the datapoints according to their cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choosing the number of n_clusters without extra information is not trivial. For these blobs data, we don't have any labels. Which configurations do you think are be the best for this dataset? How many n_custers would you choose?\n",
    "- Run the KMeans algorithm with your n_cluster parameter and plot your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Spiral dataset\n",
    "Now we try to use the KMeans algorithm to cluster the Spiral dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "spiral = np.load(\"spiral.npz\")['x']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use sklearn kmeans to cluster points and visualize it similar than before with the blob dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does it work? Please explain your answer, which assumptions required for kmeans? \n",
    "- What limitations do you think K-means would have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) sklearn mean-shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we do the same task as before but with the mean shift algorithm instead of kmeans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) Toy dataset: blobs\n",
    "\n",
    "- Use sklearn meanshift function to cluster points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot clustering results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try different hyper-parameters (i.e. bandwidth, which is an important parameter for mean-shift) and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b) Toy dataset: spiral\n",
    "\n",
    "- Use the Mean-shift to cluster the Spiral dataset.\n",
    "- Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does it work?\n",
    "- What kind of data cluster is this approach better at discovering?\n",
    "- (Optional) Brainstorm: do you have a solution for this dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CElYwyIUrths"
   },
   "source": [
    "As we have seen in 3), the data is imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSS90jWjrths"
   },
   "source": [
    "### 5a) Training with under-sampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5VApKhjrths"
   },
   "source": [
    "- print the size of the smallest class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntpS5FC3rths",
    "outputId": "63b35c52-c0fc-49a0-863d-c9defc8b7141"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_cVeXGhrths"
   },
   "source": [
    "- Undersample all the majority classes so that all classes has the same smallest cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viFhweFUrths"
   },
   "outputs": [],
   "source": [
    "# subsets for each class, using .query()\n",
    "# downsample each subset, using .sample()\n",
    "# concatenate the seven subsets, using .concat(), and shuffle the data (using .sample() on the full set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGUKsPZgrtht"
   },
   "source": [
    "- check the class distribution of the undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoOhrTaortht",
    "outputId": "e10cb9c5-c7bc-4bb8-c9a9-bfec39f2e33e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YY2NfiWqrtht"
   },
   "source": [
    "- Preprocessing data (define X, y; train test split; normalize data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLdDuAofrtht",
    "outputId": "136bba34-147c-41ea-a974-aa7b30d32b7a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-vWa2ubrtht"
   },
   "source": [
    "- Train and test the random forest classifier on under-sampled data\n",
    "- Print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoYv8yU-rtht",
    "outputId": "8a776bde-c7e9-47c5-c200-98942dfc3144"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rY_V-k52rtht"
   },
   "source": [
    "### 5b) Training with over-sampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cL-iJsenrtht"
   },
   "source": [
    "- print the size of the largest class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_OGz1Pnrthu",
    "outputId": "90a33637-1aff-4173-b394-654a8b15ef66"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxIKAEb5rthu"
   },
   "source": [
    "- Oversample the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nB6IuwAKrthu"
   },
   "outputs": [],
   "source": [
    "# subsets for each class, using .query()\n",
    "# oversample each subset, using .sample()\n",
    "# concatenate the seven subsets, using .concat(), and shuffle the data (using .sample() on the full set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qp7uUC71rthu"
   },
   "source": [
    "- check the class distribution of the oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M467hG7mrthu",
    "outputId": "077d8017-c15b-476c-94d7-4030d067fb6b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8UOYt3arthu"
   },
   "source": [
    "- Preprocessing data (define X, y; train test split; normalize data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmPs7BD8rthu",
    "outputId": "71822087-9f22-48e4-b91e-fa4ef0629d41"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f86O3VhJrthv"
   },
   "source": [
    "- Train and test the random forest classifier on over-sampled data\n",
    "- Print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9euGcCwrthv",
    "outputId": "03d4c50d-cb9e-4b2c-cb39-b308b651dfa7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEtnOTW9rthv"
   },
   "source": [
    "### Conclusion on imbalanced data solution (with random forest classifier):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:\n",
    "\n",
    "- imbalanced data:\n",
    "\n",
    "- undersampled data: \n",
    "\n",
    "- oversampled data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNAUQkeFrthv"
   },
   "source": [
    "There is a bit of cheating in over-sampling: Some of the data are copied both in train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8etAY0b4rthv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
