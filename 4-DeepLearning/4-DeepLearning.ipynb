{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18679ef9",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning for Plant Sciences (ML4PS2025) - Deep Learning lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648c200",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Python has multiple high quality libraries for Deep Learning: **torch**, **tensorflow**, **keras**. \n",
    "\n",
    "These libraries are standard, documented, fairly easy to use and highly optimized. Within their ecosystem, they cover all components and aspects of the trade: data processing and loading, model design and training, optimization and parallelization, testing and evaluating.\n",
    "\n",
    "Here are some libraries within this ecosystem that may be useful:\n",
    "- **numpy** for handling data\n",
    "- **pandas** for working with datasets\n",
    "- **scipy** for optimization and maths problems\n",
    "- **rasterio** for handling raster data (eg satellite imagery)\n",
    "- **sklearn** for metrics and testing\n",
    "- **wandb** (Weight and Biases) for hyperparameter tuning and keeping track of models trained\n",
    "- **lightning** (on top of **pytorch**) for scalability and deployment with **pytorch**\n",
    "... and so many more!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ceabf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2f589",
   "metadata": {},
   "source": [
    "### Training a Computer Vision model\n",
    "\n",
    "Simple classification framework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "def evaluate_model(model, loader):\n",
    "    \"\"\"Get predictions and true labels\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "temp_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset_temp = OxfordIIITPet(root='./data', split='trainval', download=True, transform=temp_transform) # Temporary\n",
    "temp_loader = DataLoader(dataset_temp, batch_size=32, shuffle=False) # Temporary\n",
    "\n",
    "def compute_mean_std(loader):\n",
    "    \"\"\"Compute mean and std for normalization\"\"\"\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images += batch_samples\n",
    "\n",
    "    mean /= total_images\n",
    "    std /= total_images\n",
    "    return mean, std\n",
    "\n",
    "mean, std = compute_mean_std(temp_loader)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean.tolist(), std.tolist())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d39e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load official datasets\n",
    "trainval_dataset = OxfordIIITPet(root='./data', split='trainval', transform=transform)\n",
    "test_dataset  = OxfordIIITPet(root='./data', split='test', transform=transform)\n",
    "class_names = trainval_dataset.classes\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset, val_dataset = train_test_split(trainval_dataset, test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2347af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "num_classes = len(class_names)\n",
    "print(f\"{len(train_dataset)} images (in train set) - {len(val_dataset)} images (in val set) - {len(test_dataset)} images (in test set) \\n{num_classes} classes\")\n",
    "\n",
    "# Check dataset balance\n",
    "def plot_class_distribution(dataset, class_names):\n",
    "    class_counts = [0] * len(class_names)\n",
    "    for _, label in dataset:\n",
    "        class_counts[label] += 1\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(class_names, class_counts)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Number of images')\n",
    "    plt.title('Class Distribution')\n",
    "    plt.show() \n",
    "\n",
    "plot_class_distribution(train_dataset, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f956ad",
   "metadata": {},
   "source": [
    " #### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f65c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN model\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        #self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = torch.nn.Linear(16 * 112 * 112, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "model = SimpleCNN(num_classes=len(class_names)) # Model instantiation\n",
    "\n",
    "# Display the architecture of the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ba36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "criterion = torch.nn.CrossEntropyLoss() # Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # Optimizer\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses = list(), list()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # training mode\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    model.eval()  # evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f}')\n",
    "print('Training complete')\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(range(num_epochs), train_losses, label='Train Loss')\n",
    "plt.plot(range(num_epochs), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd84dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "all_labels, all_preds = evaluate_model(model, train_loader)\n",
    "print(f\"Accuracy on train set: {accuracy_score(all_labels, all_preds)}\")\n",
    "\n",
    "all_labels, all_preds = evaluate_model(model, test_loader)\n",
    "print(f\"Accuracy on test set: {accuracy_score(all_labels, all_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43391ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO improve the model\n",
    "\n",
    "# TODO change the learning rate, number of epochs, batch size\n",
    "\n",
    "# TODO think about overfitting: regularization, dropout, data augmentation, early stopping\n",
    "\n",
    "# TODO add more metrics: confusion matrix, F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed9c53",
   "metadata": {},
   "source": [
    "#### More real use case: using a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet18\n",
    "resnet_model = models.resnet18(weights=\"ResNet18_Weights.IMAGENET1K_V1\") # Model instantiation\n",
    "resnet_model.fc = torch.nn.Linear(resnet_model.fc.in_features, num_classes) # Adapt last layer to current use case\n",
    "\n",
    "# Display the architecture of the model\n",
    "print(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ceb1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "criterion = torch.nn.CrossEntropyLoss() # Loss function\n",
    "optimizer = torch.optim.AdamW(resnet_model.parameters(), lr=1e-4, weight_decay=1e-4) # Optimizer\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses = list(), list()\n",
    "for epoch in range(num_epochs):\n",
    "    resnet_model.train() # training mode\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    resnet_model.eval()  # evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = resnet_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f}')\n",
    "print('Training complete')\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(range(num_epochs), train_losses, label='Train Loss')\n",
    "plt.plot(range(num_epochs), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f47365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO evaluate the ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91547cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Try freezing all layers but the classifier head and retrain\n",
    "if False:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d800a8",
   "metadata": {},
   "source": [
    "#### So what is actually going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check the output of the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df93cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO dive into class wise metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c607d8c",
   "metadata": {},
   "source": [
    "### Doing image segmentation\n",
    "\n",
    "Try doing it all yourself on an image segmentation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4acbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torch.utils.data import DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Standard ImageNet normalization values\n",
    "IMAGE_NET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGE_NET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "def denormalize(img):\n",
    "    \"\"\"Denormalize an ImageNet image tensor for visualization.\"\"\"\n",
    "    mean = torch.tensor(IMAGE_NET_MEAN).view(3,1,1)\n",
    "    std = torch.tensor(IMAGE_NET_STD).view(3,1,1)\n",
    "    img = img * std + mean \n",
    "    img = img.permute(1,2,0) \n",
    "    img = img.clamp(0,1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da49d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms for images and masks\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGE_NET_MEAN, IMAGE_NET_STD)\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.PILToTensor(), \n",
    "])\n",
    "\n",
    "# Load dataset (with masks)\n",
    "dataset = OxfordIIITPet(\n",
    "    root='./data', \n",
    "    download=True, \n",
    "    transform=img_transform, \n",
    "    target_types='segmentation'\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    masks = torch.stack([mask_transform(item[1]) for item in batch])\n",
    "    return images, masks\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Load pretrained U-Net (encoder pretrained on ImageNet)\n",
    "model = smp.Unet(encoder_name=\"resnet18\", encoder_weights=\"imagenet\", in_channels=3, classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "model.eval()\n",
    "\n",
    "images, masks = next(iter(loader)) \n",
    "masks = masks.float() / masks.max() # Convert masks to 0/1 (background vs pet)\n",
    "with torch.no_grad():\n",
    "    images_resized = torch.nn.functional.interpolate(images, size=(128,128))\n",
    "    outputs = model(images_resized)\n",
    "    preds = torch.sigmoid(outputs)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 12))\n",
    "for i in range(4):\n",
    "    axes[i,0].imshow(denormalize(images[i]))\n",
    "    axes[i,0].set_title(\"Image\")\n",
    "    axes[i,0].axis('off')\n",
    "    \n",
    "    axes[i,1].imshow(masks[i][0], cmap='gray')\n",
    "    axes[i,1].set_title(\"True Mask\")\n",
    "    axes[i,1].axis('off')\n",
    "    \n",
    "    axes[i,2].imshow(preds[i][0], cmap='gray')\n",
    "    axes[i,2].set_title(\"Pred Mask\")\n",
    "    axes[i,2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad603002",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = next(iter(loader)) \n",
    "\n",
    "masks.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718eaaee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4PSenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
