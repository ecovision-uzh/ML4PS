{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2221d9ce0419513808069487a0bbb7a240bfa6db"
   },
   "source": [
    "# Project Air Quality\n",
    "You will be asked to implement several functions. Team work is not allowed. Everybody implements his/her own code. Discussing issues with others is fine, sharing code with others is not. \n",
    "\n",
    "### Dataset: Air quality\n",
    "The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level, within an Italian city. Data were recorded from March 2004 to February 2005 (one year) representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2) and were provided by a co-located reference certified analyzer [1].\n",
    "\n",
    "**Attributes of the dataset are:**\n",
    "\n",
    "|Sl No|Attribute|Description|\n",
    "|-|-|-|\n",
    "|0|Date|Date (DD/MM/YYYY) |\n",
    "|1|Time|Time (HH.MM.SS) |\n",
    "|2|CO(GT)|True hourly averaged concentration CO in mg/m^3 (reference analyzer) |\n",
    "|3|PT08.S1(CO)|PT08.S1 (tin oxide) hourly averaged sensor response (nominally CO targeted)|\n",
    "|4|NMHC(GT)|True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)|\n",
    "|5|C6H6(GT)|True hourly averaged Benzene concentration in microg/m^3 (reference analyzer) |\n",
    "|6|PT08.S2(NMHC)|PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted) |\n",
    "|7|NOx(GT)|True hourly averaged NOx concentration in ppb (reference analyzer) |\n",
    "|8|PT08.S3(NOx)|PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) |\n",
    "|9|NO2(GT)|True hourly averaged NO2 concentration in microg/m^3 (reference analyzer) |\n",
    "|10|PT08.S4(NO2)|PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted) |\n",
    "|11|PT08.S5(O3)|PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted) |\n",
    "|12|T|Temperature in Â°C |\n",
    "|13|RH|Relative Humidity (%) |\n",
    "|14|AH|AH Absolute Humidity|\n",
    "\n",
    "\n",
    "### Problem:\n",
    "Humans are very sensitive to humidity, as the skin relies on the air to get rid of moisture. The process of sweating is your body's attempt to keep cool and maintain its current temperature. If the air is at 100-percent relative humidity, sweat will not evaporate into the air. As a result, we feel much hotter than the actual temperature when the relative humidity is high. If the relative humidity is low, we can feel much cooler than the actual temperature because our sweat evaporates easily, cooling us off. \n",
    "The humidity of the air, if it is not maintained at optimal levels, can be a factor that has adverse affects on people's health. According to reports, the human body is said to be most comfortable when the relative humidity of the area ranges between 20 and 60%.\n",
    "\n",
    "\n",
    "### Objective:\n",
    "So we will **predict the Relative Humidity** of a given point of time based on the all other attributes affecting the change in RH.\n",
    "\n",
    "\n",
    "### References:\n",
    "[1] S. De Vito, E. Massera, M. Piga, L. Martinotto, G. Di Francia, On field calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario, Sensors and Actuators B: Chemical, Volume 129, Issue 2, 22 February 2008, Pages 750-757, ISSN 0925-4005\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32af863b96dea6b55e2edb2ef9efd3b7700eeb47"
   },
   "source": [
    "### <u>Content:<u>\n",
    "\n",
    "[1) Load data ](#load_data)\n",
    "    \n",
    "[2) Basic statistics](#stat)\n",
    "\n",
    "[3) Data Cleaning](#hr)\n",
    "    \n",
    "[4) Co-relation between variables](#corr)\n",
    "\n",
    "[5) Influence of features on output-RH](#lin)\n",
    "\n",
    "[6) Baseline Linear Regression](#LR)\n",
    "\n",
    "[7) Feature Engineering and testing model](#FE)\n",
    "\n",
    "[8) Decision Tree Regression ](#DT)\n",
    "    \n",
    "[9) Random Forest Regression](#RF) \n",
    "    \n",
    "[9.1) Blox plot](#bxplot)\n",
    "\n",
    "[11) Conclusion](#conc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "3fb7e3274cdb7252c5434d45e35b5db673d83a1f"
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "import seaborn as sns\n",
    "rcParams['figure.figsize']=10,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dba61c61e778a17f4fc311b7e207268a0068c262"
   },
   "source": [
    "#### 1) Load data<a name=\"load_data\"></a>\n",
    "We will load the data and have a basic first look at the data.\n",
    "\n",
    "- Use `pandas.read_csv('path/to/dataset.csv',header=None,skiprows=1,names=col,na_filter=True, na_values=-200,usecols=use)` to load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "f3336d998053e4d1e6bc2760a7b5ed3a65b525be"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/AirQualityUCI.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m use = \u001b[38;5;28mlist\u001b[39m(np.arange(\u001b[38;5;28mlen\u001b[39m(col)))\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Reading the data from csv\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df_air = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/AirQualityUCI.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Write the path of the Air Quality Dataset\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/ML4PS/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/ML4PS/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/ML4PS/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/ML4PS/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/ML4PS/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/AirQualityUCI.csv'"
     ]
    }
   ],
   "source": [
    "# Defining header\n",
    "col=['DATE','TIME','CO_GT','PT08_S1_CO','NMHC_GT','C6H6_GT','PT08_S2_NMHC',\n",
    "     'NOX_GT','PT08_S3_NOX','NO2_GT','PT08_S4_NO2','PT08_S5_O3','T','RH','AH']\n",
    "\n",
    "# Defining number of columns from csv\n",
    "use = list(np.arange(len(col)))\n",
    "\n",
    "# Reading the data from csv\n",
    "df_air = pd.read_csv(\n",
    "    'data/AirQualityUCI.csv',  # Write the path of the Air Quality Dataset\n",
    "    header=None, skiprows=1, names=col, na_filter=True, na_values=-200, usecols=use\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize the first and the last 7 rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the dtypes in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b2d9d7360f167bb682326d368c544cec164fd87f"
   },
   "outputs": [],
   "source": [
    "df_air.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print dataframe shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11cfab56463119e89386f321ae32a8f4ddba59d2"
   },
   "source": [
    "#### 2) Basic statistics<a name=\"stat\"></a>\n",
    "Here we look at basic statistics. This is always helpful to get a feel for your data and might help to find some problems in your data.\n",
    "- Print dataframe statistics (mean, max & min values for each column etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea0865fdc8a2076e90f2f817c6af255cc3090630"
   },
   "outputs": [],
   "source": [
    "df_air.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe4cf230d2c14cbbcef7e26ebbb249777cfa7cb3"
   },
   "source": [
    "#### 3) Data Cleaning<a name=\"hr\"></a>\n",
    "Here we clean up some missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop **ONLY** rows containing **ALL** NaN (not a number) values \n",
    "- NOTE: You can use `inplace=True` (See: https://www.geeksforgeeks.org/what-does-inplace-mean-in-pandas/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air.dropna(how='all', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, drop **ONLY** rows with the `thresh=10` NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air.dropna(thresh=10, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1407b610322a53bdebc1a3e780ddf6f39576672"
   },
   "source": [
    "- How many missing values are in the dataset? Print the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82434c01f32fbdfcce4cd5ffa11420bfa3c6d0a5"
   },
   "outputs": [],
   "source": [
    "print('Count of missing values:\\n')\n",
    "# Count the invalid values\n",
    "df_air.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d1a542166144081d9ed6137aabfc876dd60c78c"
   },
   "source": [
    "##### Fill missing value strategy\n",
    "1. CO_GT, NOX_GT, NO2_GT will be filled by monthly average of that particular hour\n",
    "2. NHHC_GT will be dropped as it has 90% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca1b7224f6881bbc382ce8507d27ed51e12de709"
   },
   "outputs": [],
   "source": [
    "df_air['DATE'] = pd.to_datetime(df_air.DATE, format='%m/%d/%Y')   #Format date column (See: https://docs.python.org/3/library/datetime.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3dd1ffa6086d61b5e0b8535647eb896656f247d8"
   },
   "outputs": [],
   "source": [
    "# Creating \"MONTH\" column\n",
    "df_air['MONTH']=df_air.index.month     \n",
    "df_air.reset_index(inplace=True) # Run this line only once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0bec75167ae46be9682010443ee73362e5794f8d"
   },
   "outputs": [],
   "source": [
    "# Splitting hour from time into new column (See: https://docs.python.org/3/library/stdtypes.html#string-methods)\n",
    "df_air['HOUR'] = df_air['TIME'].apply(lambda x: int(x.split(':')[0]))\n",
    "df_air.HOUR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set DATE as the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91de63e7fd5b6404b437ed995f3071f9b57b76f7"
   },
   "outputs": [],
   "source": [
    "df_air.set_index('DATE', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77ebd67e6a32310fcc8f7943c538cd7c7f0ebd63"
   },
   "source": [
    "- Drop column NMHC_GT; it has 90% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "000a361345a4469fc300d883a1275876793100d0"
   },
   "outputs": [],
   "source": [
    "df_air.drop(columns='NMHC_GT', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59d7d8a65eb3a4f6d9c26793723cfaedfe3b0880"
   },
   "source": [
    "- Fill NaN values with monthly average of particular hour  (See: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) HINT: use `.groupby(['MONTH','HOUR'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f00bc5da96c4db8d2d23a704fa45321cfeaeb682"
   },
   "outputs": [],
   "source": [
    "df_air['CO_GT']=df_air['CO_GT'].fillna(df_air.groupby(['MONTH','HOUR'])['CO_GT'].transform('mean'))\n",
    "df_air['NOX_GT']=df_air['NOX_GT'].fillna(df_air.groupby(['MONTH','HOUR'])['NOX_GT'].transform('mean'))\n",
    "df_air['NO2_GT']=df_air['NO2_GT'].fillna(df_air.groupby(['MONTH','HOUR'])['NO2_GT'].transform('mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print missing values per attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0b5243ab00b71b52fa0a102e317a6d9c64d9f97"
   },
   "outputs": [],
   "source": [
    "print('Left out missing value:')\n",
    "# Count them\n",
    "df_air.shape[0] - df_air.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Fill NaN values with hourly average value HINT: use `.groupby(['HOUR'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07f1ae983958da0bf9af2294836a865c8bb69f5c"
   },
   "outputs": [],
   "source": [
    "# Filling left out NaN values with hourly average value\n",
    "df_air['CO_GT'] = df_air['CO_GT'].fillna(df_air.groupby(['HOUR'])['CO_GT'].transform('mean'))\n",
    "df_air['NOX_GT'] = df_air['NOX_GT'].fillna(df_air.groupby(['HOUR'])['NOX_GT'].transform('mean'))\n",
    "df_air['NO2_GT'] = df_air['NO2_GT'].fillna(df_air.groupby(['HOUR'])['NO2_GT'].transform('mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a390f0e9e8b4950475913663213bcd833f8cbeb6"
   },
   "source": [
    "#### 4) Understand correlation between variables<a name=\"corr\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Display a heatmap using `sns.heatmap` to see correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f66b54be3ee221420ba23c9f218451680ac2f41",
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df_air.select_dtypes(include=\"number\").corr(), annot=True, cmap='BuGn', fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Describe the heatmap using your own words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fe8d6fcdfaaa654c94beedbb693a04ddadf536e"
   },
   "source": [
    "#### 5) Try to understand degree of linearity between RH output and other input features<a name=\"lin\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - plot all features (x-axis) against output variable RH (y-axis) using `sns.lmplot`. \n",
    " - describe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d6bdaf849efada7176e4fd3d13ca7eb5f1fa484",
    "hideCode": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ensure numeric columns are properly converted\n",
    "df_air = df_air.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Exclude non-numeric columns from plotting\n",
    "numeric_columns = df_air.select_dtypes(include=\"number\").columns\n",
    "\n",
    "\n",
    "# Plot all numeric features against output variable RH\n",
    "fig, axes = plt.subplots(2, 8, figsize=(20, 7))\n",
    "for i, feature in enumerate(numeric_columns):\n",
    "    sns.regplot(data=df_air, x=feature, y='RH', ax=axes[i // 8, i % 8], line_kws=dict(color=\"#4ea373\"), color=\"gray\", marker='.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANSWER: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdea423dd5a6909235b58e471b4400c6b13cce25"
   },
   "source": [
    "### 6) Linear Regression<a name=\"LR\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18a2075d29238b5d89d6676b731bf7ced805c2ec"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler         #import normalisation package\n",
    "from sklearn.model_selection import train_test_split      #import train test split\n",
    "from sklearn.linear_model import LinearRegression         #import linear regression package\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error   #import mean squared error and mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8cfe7db69f4cbaa5c07e56de9aae8eb79f7fb5f"
   },
   "source": [
    "- Define Feature (as X) and Target (as y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37cb056fb7da95fa970bf47375b9fae7d2324bb2"
   },
   "outputs": [],
   "source": [
    "X = df_air.drop(columns=['DATE', 'TIME', 'RH'])  # X-input features\n",
    "y = df_air['RH']  # y-input features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot distribution of target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_air, x=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44530f9871590d84d917d8823110e38ff24fb56b"
   },
   "source": [
    "##### Train test split:\n",
    " - split the data into train (70%) and test(30%), use a fixed random seed\n",
    " - print the size of the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c807208b968db8fd484a7fb94cc01bc85ba9278"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6da09964d8a20171a1cf8fb0b4ecd2d25bf582ba"
   },
   "outputs": [],
   "source": [
    "print('Training data size:')\n",
    "print(X_train.shape)\n",
    "\n",
    "print('Test data size:')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7231f2173db0d89b411e0f97766f690a8a2820ff"
   },
   "source": [
    "- Normalize data using `StandardScaler`\n",
    "    - Be careful about which data you use to fit the normalization.\n",
    "    - apply the same normalisation to the test data as to the train data\n",
    "    - DO NOT forget to use the normalization for each model (SVR etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e962d38ebed67ad1c22620367a0d86dc6bde59bc"
   },
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "45bb5e52af895a267c874a8dd18ac6cd6ad98f22"
   },
   "source": [
    " - Train the Linear Regression model (See: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "159571147e44944d8b92f804e1e3a8a6fda0784e"
   },
   "outputs": [],
   "source": [
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print intercept and slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc5bf141431b1bc0e87c6ec4355ed13d74ad733b"
   },
   "outputs": [],
   "source": [
    "print('Intercept: \\t\\t\\t\\t{}'.format(model_lr.intercept_))\n",
    "for slope, key in zip(model_lr.coef_, X.keys()):\n",
    "    print('Slope of {:20}: \\t\\t{}'.format(key, slope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict on the test data\n",
    "- Compute and print performance metrics as RMSE. This will be our baseline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9eb76c8a7d964fcc3e0975de450921802d8468e4"
   },
   "outputs": [],
   "source": [
    "print('Baseline RMSE:')\n",
    "y_pred = model_lr.predict(X_test)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "baseline_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e0b12a8d38da8d0994b1169be384e3992e3c1280"
   },
   "source": [
    "#### <u>6a) Conclusion of baseline linear regression model:<a name=\"LRcon\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your conclusion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b97f6943c00521d768fd9e225dcaa6d4ed5ad29"
   },
   "source": [
    "### 7) Feature engineering and testing model:<a name=\"FE\"></a>\n",
    "\n",
    "We will try the model with multiple feature combination and see if RMSE is improving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fc53443f0abbb1bb8f932b4e76939088a62b0c7a"
   },
   "source": [
    "- Write function to measure RMSE with different combinations of features (try at least 3 combinations of your choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b917e0c10ce602ff97e72786b1f9fa9a05a99e63"
   },
   "outputs": [],
   "source": [
    "def train_test_RMSE(df_air, feat_):    \n",
    "    \"\"\"\n",
    "    The function train_test_RMSE returns the RMSE for different combinations \n",
    "    of features feat_ of the dataframe df_air.\n",
    "    \n",
    "        :param df_air: (pandas.DataFrame) Our dataset\n",
    "        :param feat_: (List[str]) A list of column names\n",
    "        :return: (float) The score value\n",
    "    \"\"\"\n",
    "    X = df_air[feat_]\n",
    "    y = df_air['RH']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    normalizer = StandardScaler()\n",
    "    X_train = normalizer.fit_transform(X_train)\n",
    "    X_test = normalizer.transform(X_test)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1b4f81132b6dc1a86095dc0ef363ef71c9aeeb8"
   },
   "outputs": [],
   "source": [
    "# Trail 1\n",
    "train_test_RMSE(df_air, X.keys()[3:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3fcd6877c683d5335f94e6fa44190f33bdec2fb"
   },
   "outputs": [],
   "source": [
    "# Trail 2\n",
    "train_test_RMSE(df_air, X.keys()[5:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2df7fa42452f0d987f988ca4b0c64a7b32d7b939"
   },
   "outputs": [],
   "source": [
    "# Trail 3\n",
    "train_test_RMSE(df_air, X.keys()[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d434585b7284b2e87a49a69eb7394ff7b0fe23c"
   },
   "source": [
    "#### <u>7a) Conclusion of Feature Engineering and testing:<a name=\"FEcon\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your conclusion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c9b4dd7c82bf372612fdb301c7ed59dbf93781d7"
   },
   "source": [
    "### 8) Decision Tree Regression<a name=\"DT\"></a>\n",
    "\n",
    "Let us try to apply Decision tree regression technique and see if any improvement happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ece8c66fa537470bc165472221ea3eb7fc371ac"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor         # Decision tree regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0cd00140f7405c5d213fd37af8776867b40b98ee"
   },
   "source": [
    "- Fit the DT model and predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e521980e8e0c531358cbd0871709268feb382df1"
   },
   "outputs": [],
   "source": [
    "model_dt = DecisionTreeRegressor()\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred = model_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48f647b2e5e46d5bad3988bf0475ef0bc7237013"
   },
   "source": [
    "- calculate the RMSE of RH prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8746927d99271c2ddda379c45a4aef3035e997ab"
   },
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "print('RMSE of Decision Tree Regression:')\n",
    "np.sqrt(mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eaa340d761a6f2eeddb8982912f2e1f304019562"
   },
   "source": [
    "#### <u>Conclusion:<u>(Decision Tree Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your conclusion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4904dbd6ee5dfcddc63d1d580c15586195b9b5c9"
   },
   "source": [
    "### 9) Random Forest Regression<a name=\"RF\"></a>\n",
    "\n",
    "Let's apply Random Forest regression and measure RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15cdc478bbd1d46d4e576e84e878df5be1b850c9"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor           # Import random forest regressor\n",
    "from sklearn.model_selection import GridSearchCV       # Import grid search cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a943435d37f60e8281ca0360283b37cb0669813"
   },
   "source": [
    "- Fit the RF model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64b4eb02c2bca90f571a5782499f48de0245b965"
   },
   "outputs": [],
   "source": [
    "model_rf = RandomForestRegressor()\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bfcd4f1a0ff4136bcecfe113a890d517ef198183"
   },
   "source": [
    "- RMSE of RH prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d2c6f2b866fdc699dd10608a094132e7b2621b6"
   },
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "print('RMSE of predicted RH in RF model:')\n",
    "np.sqrt(mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be1732d23226a6134376336680d3fc18514324d1"
   },
   "source": [
    "- Try to improve on baseline RF model: use `GridSearchCV` to search between different hyperparameters and plot the resulting RMSE\n",
    "    - use different numbers of estimators\n",
    "    - use cv of 5 or 10\n",
    "    - use the correct scoring function\n",
    "    - then, use the best model hyperparameters to predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36b4737670e2c8e3a4363b19e01c4e92eb9bab0d"
   },
   "outputs": [],
   "source": [
    "grid_searcher = GridSearchCV(model_rf, {'n_estimators': [10, 15, 100]}, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d31104659e78c45aded09b884ca55c7dbec27cf"
   },
   "outputs": [],
   "source": [
    "model_rf2 = grid_searcher.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rf2.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a56923a2a9049104c7f82a588c03296d369b2404"
   },
   "outputs": [],
   "source": [
    "print('RMSE using RF grid search method')  \n",
    "np.sqrt(mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write here your conclusions regarding the Grid Search method. Did the performance improve? How much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1) Plot box plots of the error <a name=\"bxplot\"></a>\n",
    "- Plot the box plots of absolute errors at different pridiction range (prediction: <20; 20-40; >40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = abs(y_test - y_pred)\n",
    "df_errors = pd.DataFrame(data={'error': error, 'target': y_test, 'prediction': y_pred})\n",
    "data = [\n",
    "    df_errors[df_errors['prediction'] < 20]['error'].to_numpy(),\n",
    "    df_errors[(df_errors['prediction'] >= 20) & (df_errors['prediction'] < 40)]['error'].to_numpy(),\n",
    "    df_errors[df_errors['prediction'] >= 40]['error'].to_numpy(),\n",
    "]\n",
    "sns.boxplot(data=data, showfliers=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b5f0b96cc0e6a21fbf588ecb622795f91d57deb9"
   },
   "source": [
    "#### <u>Conclusion: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write conclusion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7c7f98858b5f4bdaf0a53139127847fbe90a614"
   },
   "source": [
    "### Conclusion<a name=\"conc\"></a>\n",
    "\n",
    " - Summarize here your conclusions regarding the models used \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4PS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
